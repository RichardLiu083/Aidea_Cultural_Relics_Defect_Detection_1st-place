{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f515646f",
   "metadata": {},
   "source": [
    "nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48176055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import mmdet\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def set_random_seed(seed, deterministic=False):\n",
    "    \"\"\"Set random seed.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(dataset):\n",
    "    print('checking dataset')\n",
    "    \n",
    "    drop_sample= []\n",
    "    for i in range(len(dataset)):\n",
    "\n",
    "        data= dataset[i]\n",
    "        img_shape= Image.open(data['image_path']).size\n",
    "        bbox= data['bbox']\n",
    "\n",
    "        drop_indx= []\n",
    "        for j in range(len(bbox)):\n",
    "            if bbox[j][2]>=img_shape[0]: bbox[j][2]= img_shape[0] - 1\n",
    "            if bbox[j][3]>=img_shape[1]: bbox[j][3]= img_shape[1] - 1\n",
    "            if bbox[j][0]<=0: bbox[j][0]= 0\n",
    "            if bbox[j][1]<=0: bbox[j][1]= 0\n",
    "            if bbox[j][2]<=bbox[j][0] or bbox[j][3]<=bbox[j][1]:\n",
    "                drop_indx.append(j)\n",
    "\n",
    "        data['bbox']= np.delete(data['bbox'], drop_indx, axis= 0)\n",
    "        data['label']= np.delete(data['label'], drop_indx, axis= 0)\n",
    "\n",
    "        if len(data['bbox'])==0:\n",
    "            drop_sample.append(i)\n",
    "\n",
    "    dataset= np.delete(dataset, drop_sample, axis= 0)\n",
    "    if drop_sample!=[]: print('remove empty bboxes data: {}'.format(len(drop_sample)))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5449a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class DefectDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('1', '2', '3', '4', '5')\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        all_dataset= []\n",
    "        with open('Data/train_1.json', 'r', encoding=\"utf-8\") as f:\n",
    "            label= json.load(f)\n",
    "        for i in range(len(label['images'])):\n",
    "            data= {}\n",
    "            data['image_path']= 'Data/train_img_1/' + label['images'][i]['file_name']\n",
    "            data['bbox']= []\n",
    "            data['label']= []\n",
    "            id= label['images'][i]['id']\n",
    "\n",
    "            for j in range(len(label['annotations'])):\n",
    "                if id==label['annotations'][j]['image_id']:\n",
    "                    box= label['annotations'][j]['bbox']\n",
    "                    box[2]+= box[0]\n",
    "                    box[3]+= box[1]\n",
    "                    data['bbox'].append(box)\n",
    "                    data['label'].append(label['annotations'][j]['category_id']-1)\n",
    "            all_dataset.append(data)\n",
    "            \n",
    "        # PL\n",
    "        conf_thr= 0.2\n",
    "        df= pd.read_csv('Data/submission_0.475_1234+5.csv')\n",
    "        df= df[df['confidence']>conf_thr]\n",
    "\n",
    "        all_img_name= list(set(df['image_filename']))\n",
    "        for name in all_img_name:\n",
    "            data= df[df['image_filename']==name]\n",
    "            bbox= data[['x', 'y', 'w', 'h']].values\n",
    "            for i in range(len(bbox)):\n",
    "                bbox[i][2]+= bbox[i][0]\n",
    "                bbox[i][3]+= bbox[i][1]\n",
    "            label= data['label_id']\n",
    "\n",
    "            data= {}\n",
    "            data['image_path']= f'Data/test_img/{name}'\n",
    "            data['bbox']= np.array(bbox)\n",
    "            data['label']= np.array(label)-1\n",
    "            all_dataset.append(data)\n",
    "            \n",
    "        # select class\n",
    "        keep_classes= [0,1,2,3,4]\n",
    "        drop_sample= []\n",
    "        for i, data in enumerate(all_dataset):\n",
    "\n",
    "            bbox= data['bbox']\n",
    "            label= data['label']\n",
    "\n",
    "            drop_indx= []\n",
    "            for j in range(len(label)):\n",
    "                if label[j] not in keep_classes:\n",
    "                    drop_indx.append(j)\n",
    "\n",
    "            data['bbox']= np.delete(bbox, drop_indx, axis= 0)\n",
    "            data['label']= np.delete(label, drop_indx, axis= 0)\n",
    "\n",
    "            if len(data['bbox'])==0: drop_sample.append(i)\n",
    "\n",
    "        all_dataset= np.delete(all_dataset, drop_sample, axis= 0)\n",
    "        \n",
    "        \n",
    "        # check dataset\n",
    "        all_dataset= check_dataset(all_dataset)\n",
    "            \n",
    "        # remove too many box img\n",
    "        drop_indx= []\n",
    "        for i, data in enumerate(all_dataset):\n",
    "\n",
    "            bbox= data['bbox']\n",
    "            bbox= np.array(bbox).astype(np.int)\n",
    "\n",
    "            if len(bbox)>120:\n",
    "                drop_indx.append(i)\n",
    "                continue\n",
    "\n",
    "        vali_dataset= np.array(all_dataset)[drop_indx]\n",
    "        train_dataset= np.delete(all_dataset, drop_indx, axis= 0)\n",
    "        \n",
    "        if self.ann_file=='val.txt':\n",
    "            train_dataset= vali_dataset\n",
    "            \n",
    "        # make mmdetection custom data format\n",
    "        data_infos= []\n",
    "        for data in train_dataset:\n",
    "            (width, height)= Image.open(data['image_path']).size\n",
    "            info= dict(filename= data['image_path'], width= width, height= height)\n",
    "            \n",
    "            info['ann']= {}\n",
    "            info['ann']['bboxes']= np.array(data['bbox']).astype(np.float16)\n",
    "            info['ann']['labels']= np.array(data['label']).astype(np.int)\n",
    "            data_infos.append(info)\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('configs/cascade_rcnn/cascade_rcnn_x101_32x4d_fpn_1x_coco.py')\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'DefectDataset'\n",
    "cfg.data_root = './'\n",
    "\n",
    "cfg.data.train.type = 'DefectDataset'\n",
    "cfg.data.train.data_root = ''\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = ''\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'DefectDataset'\n",
    "cfg.data.val.data_root = ''\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = ''\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head[0].num_classes = 5\n",
    "cfg.model.roi_head.bbox_head[1].num_classes = 5\n",
    "cfg.model.roi_head.bbox_head[2].num_classes = 5\n",
    "\n",
    "cfg.load_from = 'model/cascade_rcnn_x101_32x4d_fpn_1x_coco_20200316-95c2deb6.pth'\n",
    "cfg.load_from = 'test_model/k4krcnn_1000_0.420.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer= dict(type='Adam', lr=0.0003, weight_decay=0)\n",
    "cfg.optimizer.lr = 3e-5\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.lr_config.min_lr=3e-5\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.samples_per_gpu= 1\n",
    "cfg.data.workers_per_gpu= 1\n",
    "cfg.runner.max_epochs= 200\n",
    "\n",
    "# custom setting\n",
    "# cfg.model.rpn_head.loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[0].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[1].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[2].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "\n",
    "# cfg.model.rpn_head.reg_decoded_bbox= True\n",
    "# cfg.model.rpn_head.loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "# cfg.model.roi_head.bbox_head[0].reg_decoded_bbox= True\n",
    "# cfg.model.roi_head.bbox_head[0].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "# cfg.model.roi_head.bbox_head[1].reg_decoded_bbox= True\n",
    "# cfg.model.roi_head.bbox_head[1].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "# cfg.model.roi_head.bbox_head[2].reg_decoded_bbox= True\n",
    "# cfg.model.roi_head.bbox_head[2].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "\n",
    "# cfg.model.train_cfg.rcnn[0].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "# cfg.model.train_cfg.rcnn[1].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "# cfg.model.train_cfg.rcnn[2].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "\n",
    "standard_img_size= 1024\n",
    "# cfg.train_pipeline[2].img_scale= standard_img_size\n",
    "# cfg.test_pipeline[1].img_scale= standard_img_size\n",
    "cfg.train_pipeline[2].img_scale= [(4096, standard_img_size+100), (4096, standard_img_size-100)]\n",
    "cfg.train_pipeline[2].multiscale_mode='range'\n",
    "cfg.test_pipeline[1].img_scale= [(4096, standard_img_size+192),\n",
    "                                 (4096, standard_img_size+128),\n",
    "                                 (4096, standard_img_size+64),\n",
    "                                 (4096, standard_img_size),\n",
    "                                 (4096, standard_img_size-64),\n",
    "                                 (4096, standard_img_size-128),\n",
    "                                 (4096, standard_img_size-192)]\n",
    "\n",
    "cfg.data.train.pipeline= cfg.train_pipeline\n",
    "cfg.data.val.pipeline= cfg.test_pipeline\n",
    "cfg.data.test.pipeline= cfg.test_pipeline\n",
    "\n",
    "# cfg.model.backbone.norm_cfg= dict(type='GN', num_groups=32, requires_grad=True)\n",
    "cfg.model.test_cfg.rcnn.max_per_img= 300\n",
    "cfg.model.rpn_head.anchor_generator.scales= [4]\n",
    "cfg.model.rpn_head.anchor_generator.ratios= [0.5, 1.0, 2.0]\n",
    "cfg.model.backbone.dcn= dict(type='DCN', deformable_groups=1, fallback_on_stride=False)\n",
    "cfg.model.backbone.stage_with_dcn=(False, True, True, True)\n",
    "# cfg.model.backbone.gcb=dict(ratio=1./ 4.)\n",
    "# cfg.model.backbone.stage_with_gcb= (False, True, True, True)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "albu_train_transforms = [\n",
    "    dict(type=\"RandomRotate90\", p=1.0),\n",
    "    dict(\n",
    "        type='ShiftScaleRotate',\n",
    "        shift_limit=0.2,\n",
    "        scale_limit=0.2,\n",
    "        rotate_limit=10,\n",
    "        interpolation=1,\n",
    "        border_mode= 0,\n",
    "        p=0.7),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"HueSaturationValue\", hue_shift_limit=10, sat_shift_limit=35, val_shift_limit=25),\n",
    "            dict(type=\"RandomGamma\"),\n",
    "            dict(type=\"CLAHE\"),\n",
    "        ],\n",
    "        p=0.5,\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"RandomBrightnessContrast\", brightness_limit=0.2, contrast_limit=0.2),\n",
    "            #dict(type=\"RGBShift\", r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n",
    "        ],\n",
    "        p=0.5,\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"Blur\"),\n",
    "            dict(type=\"MotionBlur\"),\n",
    "            dict(type=\"GaussNoise\"),\n",
    "            dict(type=\"ImageCompression\", quality_lower=75),\n",
    "        ],\n",
    "        p=0.4,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "transforms= dict(\n",
    "        type='Albu',\n",
    "        transforms= albu_train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_labels'],\n",
    "            min_visibility=0.0,\n",
    "            filter_lost_elements=True),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            'gt_masks': 'masks',\n",
    "            'gt_bboxes': 'bboxes',\n",
    "        })\n",
    "cfg.data.train.pipeline.insert(4, transforms)\n",
    "# mixup= dict(type='MixUp',p=0.5, lambd=0.5)\n",
    "# cfg.data.train.pipeline.insert(2, mixup)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d938b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7d62983",
   "metadata": {},
   "source": [
    "best epoch: 92 0.153"
   ]
  },
  {
   "cell_type": "raw",
   "id": "738587b7",
   "metadata": {},
   "source": [
    "# img_size= 1024, anchor_scale= 4\n",
    "K4K_rcnn_x101= 0.086, score= 0.327\n",
    "\n",
    "# img_size= 1100, anchor_scale= 4, dcn, multi_scale\n",
    "K4K_rcnn_x101= 0.124, score= 0.387\n",
    "\n",
    "# img_size= 1024, anchor_scale= 3\n",
    "K4K_rcnn_r50= 0.103, score= 0.308"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bb778",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96341ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "color= [\n",
    "    (255, 0, 0), #紅\n",
    "    (0, 255, 0), #綠\n",
    "    (0, 0, 255), #藍\n",
    "    (255, 97, 0), #澄\n",
    "    (255, 0, 255), #紫\n",
    "]\n",
    "\n",
    "checkpoint_file = 'tutorial_exps/epoch_1.pth'\n",
    "#checkpoint_file= 'test_model/k4krcnn_1000_0.420.pth'\n",
    "\n",
    "cfg.data.test.pipeline[1].flip= True\n",
    "cfg.model.test_cfg.rcnn= dict(score_thr=0.0001,\n",
    "                              nms=dict(type='soft_nms',\n",
    "                                       iou_thr=0.15,\n",
    "                                       min_score=0.0001),\n",
    "                              max_per_img=300)\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "test_name= os.listdir('Data/test_img')\n",
    "test_name= ['Data/test_img/'+name for name in test_name]\n",
    "\n",
    "pred= []\n",
    "for name in tqdm(test_name[:]):\n",
    "    p= {}\n",
    "    p['img_name']= name\n",
    "    # test a single image\n",
    "    result = inference_detector(model, name)\n",
    "\n",
    "    img= cv2.imread(name)\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    all_bbox= []\n",
    "    all_label= []\n",
    "    all_score= []\n",
    "    for i in range(len(result)):\n",
    "        for box in result[i]:\n",
    "            score= box[-1]\n",
    "            all_score.append(score)\n",
    "            box= np.array(box[:4]).astype(np.int)\n",
    "            all_bbox.append(box)\n",
    "            all_label.append(i+1)\n",
    "#             if score>=0.3:\n",
    "#                 cv2.rectangle(img,\n",
    "#                               (box[0], box[1]),\n",
    "#                               (box[2], box[3]),\n",
    "#                               color[i], 10)\n",
    "\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    p['bbox']= all_bbox\n",
    "    p['label']= all_label\n",
    "    p['score']= all_score\n",
    "    pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submit= pd.DataFrame()\n",
    "\n",
    "keep_classes= [5]\n",
    "for pred in pred:\n",
    "    name= pred['img_name'].split('/')[-1]\n",
    "    bbox= pred['bbox']\n",
    "    label= pred['label']\n",
    "    score= pred['score']\n",
    "    for i in range(len(bbox)):\n",
    "        if label[i] not in keep_classes: continue\n",
    "        r= []\n",
    "        bbox[i][2]-= bbox[i][0]\n",
    "        bbox[i][3]-= bbox[i][1]\n",
    "        r+= [name]\n",
    "        r+= [label[i]]\n",
    "        r+= bbox[i].astype(np.int).tolist()\n",
    "        r+= [score[i]]\n",
    "        submit= submit.append([r], ignore_index= True)\n",
    "\n",
    "\n",
    "submit.columns= ['image_filename', \n",
    "              'label_id',\n",
    "              'x',\n",
    "              'y',\n",
    "              'w',\n",
    "              'h',\n",
    "              'confidence']\n",
    "submit.to_csv('ans.csv', index= False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
