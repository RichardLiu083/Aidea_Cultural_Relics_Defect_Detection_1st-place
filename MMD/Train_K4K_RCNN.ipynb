{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f515646f",
   "metadata": {},
   "source": [
    "nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48176055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import mmdet\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_random_seed(seed, deterministic=False):\n",
    "    \"\"\"Set random seed.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62df8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(dataset):\n",
    "    print('checking dataset')\n",
    "    \n",
    "    drop_sample= []\n",
    "    for i in range(len(dataset)):\n",
    "\n",
    "        data= dataset[i]\n",
    "        img_shape= Image.open(data['image_path']).size\n",
    "        bbox= data['bbox']\n",
    "\n",
    "        drop_indx= []\n",
    "        for j in range(len(bbox)):\n",
    "            if bbox[j][2]>=img_shape[0]: bbox[j][2]= img_shape[0] - 10\n",
    "            if bbox[j][3]>=img_shape[1]: bbox[j][3]= img_shape[1] - 10\n",
    "            if bbox[j][0]<=0: bbox[j][0]= 0\n",
    "            if bbox[j][1]<=0: bbox[j][1]= 0\n",
    "            if bbox[j][2]<=bbox[j][0] or bbox[j][3]<=bbox[j][1]:\n",
    "                drop_indx.append(j)\n",
    "\n",
    "        data['bbox']= np.delete(data['bbox'], drop_indx, axis= 0)\n",
    "        data['label']= np.delete(data['label'], drop_indx, axis= 0)\n",
    "\n",
    "        if len(data['bbox'])==0:\n",
    "            drop_sample.append(i)\n",
    "\n",
    "    dataset= np.delete(dataset, drop_sample, axis= 0)\n",
    "    if drop_sample!=[]: print('remove empty bboxes data: {}'.format(len(drop_sample)))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5449a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class DefectDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('1', '2', '3', '4', '5')\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        all_dataset= []\n",
    "        with open('Data/train_1.json', 'r', encoding=\"utf-8\") as f:\n",
    "            label= json.load(f)\n",
    "        for i in range(len(label['images'])):\n",
    "            data= {}\n",
    "            data['image_path']= 'Data/train_img_1/' + label['images'][i]['file_name']\n",
    "            data['bbox']= []\n",
    "            data['label']= []\n",
    "            id= label['images'][i]['id']\n",
    "\n",
    "            for j in range(len(label['annotations'])):\n",
    "                if id==label['annotations'][j]['image_id']:\n",
    "                    box= label['annotations'][j]['bbox']\n",
    "                    box[2]+= box[0]\n",
    "                    box[3]+= box[1]\n",
    "                    data['bbox'].append(box)\n",
    "                    data['label'].append(label['annotations'][j]['category_id']-1)\n",
    "            all_dataset.append(data)\n",
    "            \n",
    "        with open('Data/train_2.json', 'r', encoding=\"utf-8\") as f:\n",
    "            label= json.load(f)\n",
    "        for i in range(len(label['images'])):\n",
    "            data= {}\n",
    "            data['image_path']= 'Data/train_img_2/' + label['images'][i]['file_name']\n",
    "            data['bbox']= []\n",
    "            data['label']= []\n",
    "            id= label['images'][i]['id']\n",
    "\n",
    "            for j in range(len(label['annotations'])):\n",
    "                if id==label['annotations'][j]['image_id']:\n",
    "                    box= label['annotations'][j]['bbox']\n",
    "                    box[2]+= box[0]\n",
    "                    box[3]+= box[1]\n",
    "                    data['bbox'].append(box)\n",
    "                    data['label'].append(label['annotations'][j]['category_id']-1)\n",
    "            all_dataset.append(data)\n",
    "            \n",
    "        # check dataset\n",
    "        all_dataset= check_dataset(all_dataset)\n",
    "            \n",
    "        # remove too many box img\n",
    "        drop_indx= []\n",
    "        for i, data in enumerate(all_dataset):\n",
    "\n",
    "            bbox= data['bbox']\n",
    "            bbox= np.array(bbox).astype(np.int)\n",
    "\n",
    "            if len(bbox)>100:\n",
    "                drop_indx.append(i)\n",
    "                continue\n",
    "\n",
    "        vali_dataset= np.array(all_dataset)[drop_indx]\n",
    "        train_dataset= np.delete(all_dataset, drop_indx, axis= 0)\n",
    "        \n",
    "        if self.ann_file=='val.txt':\n",
    "            train_dataset= vali_dataset\n",
    "            \n",
    "        # make mmdetection custom data format\n",
    "        data_infos= []\n",
    "        for data in train_dataset:\n",
    "            (width, height)= Image.open(data['image_path']).size\n",
    "            info= dict(filename= data['image_path'], width= width, height= height)\n",
    "            \n",
    "            info['ann']= {}\n",
    "            info['ann']['bboxes']= np.array(data['bbox']).astype(np.float16)\n",
    "            info['ann']['labels']= np.array(data['label']).astype(np.int)\n",
    "            data_infos.append(info)\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e9a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://resnext101_32x4d'),\n",
      "        groups=32,\n",
      "        base_width=4,\n",
      "        dcn=dict(type='DCN', deformable_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, True, True, True)),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[4],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "        reg_decoded_bbox=True),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True)\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=300)))\n",
      "dataset_type = 'DefectDataset'\n",
      "data_root = './'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(4096, 1400), (4096, 1200)],\n",
      "        keep_ratio=True,\n",
      "        multiscale_mode='range'),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='DefectDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(4096, 1400), (4096, 1200)],\n",
      "                keep_ratio=True,\n",
      "                multiscale_mode='range'),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root=''),\n",
      "    val=dict(\n",
      "        type='DefectDataset',\n",
      "        ann_file='val.txt',\n",
      "        img_prefix='',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root=''),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='Adam', lr=3e-05, weight_decay=0)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11],\n",
      "    min_lr=3e-05)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=200)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'model/cascade_rcnn_x101_32x4d_fpn_1x_coco_20200316-95c2deb6.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('configs/cascade_rcnn/cascade_rcnn_x101_32x4d_fpn_1x_coco.py')\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'DefectDataset'\n",
    "cfg.data_root = './'\n",
    "\n",
    "cfg.data.train.type = 'DefectDataset'\n",
    "cfg.data.train.data_root = ''\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = ''\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'DefectDataset'\n",
    "cfg.data.val.data_root = ''\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = ''\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head[0].num_classes = 5\n",
    "cfg.model.roi_head.bbox_head[1].num_classes = 5\n",
    "cfg.model.roi_head.bbox_head[2].num_classes = 5\n",
    "\n",
    "cfg.load_from = 'model/cascade_rcnn_x101_32x4d_fpn_1x_coco_20200316-95c2deb6.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer= dict(type='Adam', lr=0.0003, weight_decay=0)\n",
    "cfg.optimizer.lr = 3e-5\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.lr_config.min_lr=3e-5\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.samples_per_gpu= 1\n",
    "cfg.data.workers_per_gpu= 1\n",
    "cfg.runner.max_epochs= 200\n",
    "\n",
    "# custom setting\n",
    "# cfg.model.rpn_head.loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[0].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[1].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[2].loss_cls= dict(type='FocalLoss', use_sigmoid=True, loss_weight=1.0)\n",
    "\n",
    "cfg.model.rpn_head.reg_decoded_bbox= True\n",
    "cfg.model.rpn_head.loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "cfg.model.roi_head.bbox_head[0].reg_decoded_bbox= True\n",
    "cfg.model.roi_head.bbox_head[0].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "cfg.model.roi_head.bbox_head[1].reg_decoded_bbox= True\n",
    "cfg.model.roi_head.bbox_head[1].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "cfg.model.roi_head.bbox_head[2].reg_decoded_bbox= True\n",
    "cfg.model.roi_head.bbox_head[2].loss_bbox= dict(type='GIoULoss', loss_weight=5.0)\n",
    "\n",
    "# cfg.model.train_cfg.rcnn[0].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "# cfg.model.train_cfg.rcnn[1].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "# cfg.model.train_cfg.rcnn[2].sampler= dict(type='OHEMSampler',\n",
    "#                                     num=512,\n",
    "#                                     pos_fraction=0.25,\n",
    "#                                     neg_pos_ub=-1,\n",
    "#                                     add_gt_as_proposals=True)\n",
    "\n",
    "standard_img_size= 1200\n",
    "cfg.train_pipeline[2].img_scale= [(4096, standard_img_size+100), (4096, standard_img_size-100)]\n",
    "cfg.train_pipeline[2].multiscale_mode='range'\n",
    "cfg.test_pipeline[1].img_scale= [(4096, standard_img_size+100),\n",
    "                                 (4096, standard_img_size),\n",
    "                                 (4096, standard_img_size-100)]\n",
    "\n",
    "cfg.data.train.pipeline= cfg.train_pipeline\n",
    "cfg.data.val.pipeline= cfg.test_pipeline\n",
    "cfg.data.test.pipeline= cfg.test_pipeline\n",
    "\n",
    "# cfg.model.backbone.norm_cfg= dict(type='GN', num_groups=32, requires_grad=True)\n",
    "cfg.model.test_cfg.rcnn.max_per_img= 300\n",
    "cfg.model.rpn_head.anchor_generator.scales= [4]\n",
    "cfg.model.rpn_head.anchor_generator.ratios= [0.5, 1.0, 2.0]\n",
    "cfg.model.backbone.dcn= dict(type='DCN', deformable_groups=1, fallback_on_stride=False)\n",
    "cfg.model.backbone.stage_with_dcn=(False, True, True, True)\n",
    "# cfg.model.backbone.gcb=dict(ratio=1./ 4.)\n",
    "# cfg.model.backbone.stage_with_gcb= (False, True, True, True)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871d83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://resnext101_32x4d'),\n",
      "        groups=32,\n",
      "        base_width=4,\n",
      "        dcn=dict(type='DCN', deformable_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, True, True, True)),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[4],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "        reg_decoded_bbox=True),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=5,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=5.0),\n",
      "                reg_decoded_bbox=True)\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=300)))\n",
      "dataset_type = 'DefectDataset'\n",
      "data_root = './'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(4096, 1400), (4096, 1200)],\n",
      "        keep_ratio=True,\n",
      "        multiscale_mode='range'),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Albu',\n",
      "        transforms=[\n",
      "            dict(type='RandomRotate90', p=1.0),\n",
      "            dict(\n",
      "                type='ShiftScaleRotate',\n",
      "                shift_limit=0.2,\n",
      "                scale_limit=0.2,\n",
      "                rotate_limit=180,\n",
      "                interpolation=1,\n",
      "                p=0.7),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='HueSaturationValue',\n",
      "                        hue_shift_limit=10,\n",
      "                        sat_shift_limit=35,\n",
      "                        val_shift_limit=25),\n",
      "                    dict(type='RandomGamma'),\n",
      "                    dict(type='CLAHE')\n",
      "                ],\n",
      "                p=0.5),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='RandomBrightnessContrast',\n",
      "                        brightness_limit=0.4,\n",
      "                        contrast_limit=0.4),\n",
      "                    dict(\n",
      "                        type='RGBShift',\n",
      "                        r_shift_limit=15,\n",
      "                        g_shift_limit=15,\n",
      "                        b_shift_limit=15)\n",
      "                ],\n",
      "                p=0.5),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(type='Blur'),\n",
      "                    dict(type='MotionBlur'),\n",
      "                    dict(type='GaussNoise'),\n",
      "                    dict(type='ImageCompression', quality_lower=75)\n",
      "                ],\n",
      "                p=0.4)\n",
      "        ],\n",
      "        bbox_params=dict(\n",
      "            type='BboxParams',\n",
      "            format='pascal_voc',\n",
      "            label_fields=['gt_labels'],\n",
      "            min_visibility=0.0,\n",
      "            filter_lost_elements=True),\n",
      "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes')),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='DefectDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(4096, 1400), (4096, 1200)],\n",
      "                keep_ratio=True,\n",
      "                multiscale_mode='range'),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Albu',\n",
      "                transforms=[\n",
      "                    dict(type='RandomRotate90', p=1.0),\n",
      "                    dict(\n",
      "                        type='ShiftScaleRotate',\n",
      "                        shift_limit=0.2,\n",
      "                        scale_limit=0.2,\n",
      "                        rotate_limit=180,\n",
      "                        interpolation=1,\n",
      "                        p=0.7),\n",
      "                    dict(\n",
      "                        type='OneOf',\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                type='HueSaturationValue',\n",
      "                                hue_shift_limit=10,\n",
      "                                sat_shift_limit=35,\n",
      "                                val_shift_limit=25),\n",
      "                            dict(type='RandomGamma'),\n",
      "                            dict(type='CLAHE')\n",
      "                        ],\n",
      "                        p=0.5),\n",
      "                    dict(\n",
      "                        type='OneOf',\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                type='RandomBrightnessContrast',\n",
      "                                brightness_limit=0.4,\n",
      "                                contrast_limit=0.4),\n",
      "                            dict(\n",
      "                                type='RGBShift',\n",
      "                                r_shift_limit=15,\n",
      "                                g_shift_limit=15,\n",
      "                                b_shift_limit=15)\n",
      "                        ],\n",
      "                        p=0.5),\n",
      "                    dict(\n",
      "                        type='OneOf',\n",
      "                        transforms=[\n",
      "                            dict(type='Blur'),\n",
      "                            dict(type='MotionBlur'),\n",
      "                            dict(type='GaussNoise'),\n",
      "                            dict(type='ImageCompression', quality_lower=75)\n",
      "                        ],\n",
      "                        p=0.4)\n",
      "                ],\n",
      "                bbox_params=dict(\n",
      "                    type='BboxParams',\n",
      "                    format='pascal_voc',\n",
      "                    label_fields=['gt_labels'],\n",
      "                    min_visibility=0.0,\n",
      "                    filter_lost_elements=True),\n",
      "                keymap=dict(img='image', gt_masks='masks',\n",
      "                            gt_bboxes='bboxes')),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root=''),\n",
      "    val=dict(\n",
      "        type='DefectDataset',\n",
      "        ann_file='val.txt',\n",
      "        img_prefix='',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root=''),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=[(4096, 1400), (4096, 1300), (4096, 1200)],\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='Adam', lr=3e-05, weight_decay=0)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11],\n",
      "    min_lr=3e-05)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=200)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'model/cascade_rcnn_x101_32x4d_fpn_1x_coco_20200316-95c2deb6.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "albu_train_transforms = [\n",
    "    dict(type=\"RandomRotate90\", p=1.0),\n",
    "    dict(\n",
    "        type='ShiftScaleRotate',\n",
    "        shift_limit=0.2,\n",
    "        scale_limit=0.2,\n",
    "        rotate_limit=180,\n",
    "        interpolation=1,\n",
    "        p=0.7),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"HueSaturationValue\", hue_shift_limit=10, sat_shift_limit=35, val_shift_limit=25),\n",
    "            dict(type=\"RandomGamma\"),\n",
    "            dict(type=\"CLAHE\"),\n",
    "        ],\n",
    "        p=0.5,\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"RandomBrightnessContrast\", brightness_limit=0.4, contrast_limit=0.4),\n",
    "            dict(type=\"RGBShift\", r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n",
    "        ],\n",
    "        p=0.5,\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"OneOf\",\n",
    "        transforms=[\n",
    "            dict(type=\"Blur\"),\n",
    "            dict(type=\"MotionBlur\"),\n",
    "            dict(type=\"GaussNoise\"),\n",
    "            dict(type=\"ImageCompression\", quality_lower=75),\n",
    "        ],\n",
    "        p=0.4,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "transforms= dict(\n",
    "        type='Albu',\n",
    "        transforms= albu_train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_labels'],\n",
    "            min_visibility=0.0,\n",
    "            filter_lost_elements=True),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            'gt_masks': 'masks',\n",
    "            'gt_bboxes': 'bboxes',\n",
    "        })\n",
    "cfg.data.train.pipeline.insert(4, transforms)\n",
    "# mixup= dict(type='MixUp',p=0.5, lambd=0.5)\n",
    "# cfg.data.train.pipeline.insert(2, mixup)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d938b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10057/3218338198.py:64: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bbox= np.array(bbox).astype(np.int)\n",
      "/tmp/ipykernel_10057/3218338198.py:84: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  info['ann']['labels']= np.array(data['label']).astype(np.int)\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/datasets/custom.py:156: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/utils/misc.py:323: UserWarning: \"deformable_groups\" is deprecated in `DeformConv2d.__init__`, please use \"deform_groups\" instead\n",
      "  warnings.warn(\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  warnings.warn(\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "2021-10-01 15:39:03,167 - mmdet - INFO - load checkpoint from model/cascade_rcnn_x101_32x4d_fpn_1x_coco_20200316-95c2deb6.pth\n",
      "2021-10-01 15:39:03,167 - mmdet - INFO - Use load_from_local loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-01 15:39:03,299 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([6, 1024]).\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([6, 1024]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([6, 1024]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "missing keys in source state_dict: backbone.layer2.0.conv2.conv_offset.weight, backbone.layer2.0.conv2.conv_offset.bias, backbone.layer2.1.conv2.conv_offset.weight, backbone.layer2.1.conv2.conv_offset.bias, backbone.layer2.2.conv2.conv_offset.weight, backbone.layer2.2.conv2.conv_offset.bias, backbone.layer2.3.conv2.conv_offset.weight, backbone.layer2.3.conv2.conv_offset.bias, backbone.layer3.0.conv2.conv_offset.weight, backbone.layer3.0.conv2.conv_offset.bias, backbone.layer3.1.conv2.conv_offset.weight, backbone.layer3.1.conv2.conv_offset.bias, backbone.layer3.2.conv2.conv_offset.weight, backbone.layer3.2.conv2.conv_offset.bias, backbone.layer3.3.conv2.conv_offset.weight, backbone.layer3.3.conv2.conv_offset.bias, backbone.layer3.4.conv2.conv_offset.weight, backbone.layer3.4.conv2.conv_offset.bias, backbone.layer3.5.conv2.conv_offset.weight, backbone.layer3.5.conv2.conv_offset.bias, backbone.layer3.6.conv2.conv_offset.weight, backbone.layer3.6.conv2.conv_offset.bias, backbone.layer3.7.conv2.conv_offset.weight, backbone.layer3.7.conv2.conv_offset.bias, backbone.layer3.8.conv2.conv_offset.weight, backbone.layer3.8.conv2.conv_offset.bias, backbone.layer3.9.conv2.conv_offset.weight, backbone.layer3.9.conv2.conv_offset.bias, backbone.layer3.10.conv2.conv_offset.weight, backbone.layer3.10.conv2.conv_offset.bias, backbone.layer3.11.conv2.conv_offset.weight, backbone.layer3.11.conv2.conv_offset.bias, backbone.layer3.12.conv2.conv_offset.weight, backbone.layer3.12.conv2.conv_offset.bias, backbone.layer3.13.conv2.conv_offset.weight, backbone.layer3.13.conv2.conv_offset.bias, backbone.layer3.14.conv2.conv_offset.weight, backbone.layer3.14.conv2.conv_offset.bias, backbone.layer3.15.conv2.conv_offset.weight, backbone.layer3.15.conv2.conv_offset.bias, backbone.layer3.16.conv2.conv_offset.weight, backbone.layer3.16.conv2.conv_offset.bias, backbone.layer3.17.conv2.conv_offset.weight, backbone.layer3.17.conv2.conv_offset.bias, backbone.layer3.18.conv2.conv_offset.weight, backbone.layer3.18.conv2.conv_offset.bias, backbone.layer3.19.conv2.conv_offset.weight, backbone.layer3.19.conv2.conv_offset.bias, backbone.layer3.20.conv2.conv_offset.weight, backbone.layer3.20.conv2.conv_offset.bias, backbone.layer3.21.conv2.conv_offset.weight, backbone.layer3.21.conv2.conv_offset.bias, backbone.layer3.22.conv2.conv_offset.weight, backbone.layer3.22.conv2.conv_offset.bias, backbone.layer4.0.conv2.conv_offset.weight, backbone.layer4.0.conv2.conv_offset.bias, backbone.layer4.1.conv2.conv_offset.weight, backbone.layer4.1.conv2.conv_offset.bias, backbone.layer4.2.conv2.conv_offset.weight, backbone.layer4.2.conv2.conv_offset.bias\n",
      "\n",
      "2021-10-01 15:39:03,303 - mmdet - INFO - Start running, host: foresight@fs-poweraren, work_dir: /home/foresight/AIdea/tutorial_exps\n",
      "2021-10-01 15:39:03,303 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-10-01 15:39:03,304 - mmdet - INFO - workflow: [('train', 1)], max: 200 epochs\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/home/foresight/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 10.76 GiB total capacity; 7.59 GiB already allocated; 56.44 MiB free; 8.14 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10057/230993028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create work_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 self.model, data_batch, train_mode=train_mode, **kwargs)\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             outputs = self.model.train_step(data_batch, self.optimizer,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                             **kwargs)\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data, optimizer)\u001b[0m\n\u001b[1;32m    236\u001b[0m                   \u001b[0maveraging\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 'method of nn.Module')\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, gt_masks, proposals, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             proposal_cfg = self.train_cfg.get('rpn_proposal',\n\u001b[1;32m    134\u001b[0m                                               self.test_cfg.rpn)\n\u001b[0;32m--> 135\u001b[0;31m             rpn_losses, proposal_list = self.rpn_head.forward_train(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/dense_heads/base_dense_head.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, x, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, proposal_cfg, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mproposal_list\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mProposals\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgt_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/dense_heads/anchor_head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0;32mis\u001b[0m \u001b[0mnum_anchors\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatmap_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/core/utils/misc.py\u001b[0m in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmap_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/mmdet/models/dense_heads/rpn_head.py\u001b[0m in \u001b[0;36mforward_single\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"\"\"Forward feature map of a single scale level.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mrpn_cls_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MMD/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 10.76 GiB total capacity; 7.59 GiB already allocated; 56.44 MiB free; 8.14 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7d62983",
   "metadata": {},
   "source": [
    "best epoch: 71 0.156"
   ]
  },
  {
   "cell_type": "raw",
   "id": "738587b7",
   "metadata": {},
   "source": [
    "# img_size= 1024, anchor_scale= 4\n",
    "K4K_rcnn_x101= 0.086, score= 0.327\n",
    "\n",
    "# img_size= 1100, anchor_scale= 4, dcn, multi_scale\n",
    "K4K_rcnn_x101= 0.124, score= 0.387\n",
    "\n",
    "# img_size= 1024, anchor_scale= 3\n",
    "K4K_rcnn_r50= 0.103, score= 0.308"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bb778",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96341ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "color= [\n",
    "    (255, 0, 0), #紅\n",
    "    (0, 255, 0), #綠\n",
    "    (0, 0, 255), #藍\n",
    "    (255, 97, 0), #澄\n",
    "    (255, 0, 255), #紫\n",
    "]\n",
    "\n",
    "checkpoint_file = 'tutorial_exps/epoch_72.pth'\n",
    "\n",
    "cfg.data.test.pipeline[1].flip= True\n",
    "cfg.model.test_cfg.rcnn= dict(score_thr=0.0001,\n",
    "                              nms=dict(type='soft_nms',\n",
    "                                       iou_thr=0.5,\n",
    "                                       min_score=0.0001),\n",
    "                              max_per_img=300)\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "test_name= os.listdir('Data/test_img')\n",
    "test_name= ['Data/test_img/'+name for name in test_name]\n",
    "\n",
    "pred= []\n",
    "for name in tqdm(test_name[:]):\n",
    "    p= {}\n",
    "    p['img_name']= name\n",
    "    # test a single image\n",
    "    result = inference_detector(model, name)\n",
    "\n",
    "    img= cv2.imread(name)\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    all_bbox= []\n",
    "    all_label= []\n",
    "    all_score= []\n",
    "    for i in range(len(result)):\n",
    "        for box in result[i]:\n",
    "            score= box[-1]\n",
    "            all_score.append(score)\n",
    "            box= np.array(box[:4]).astype(np.int)\n",
    "            all_bbox.append(box)\n",
    "            all_label.append(i+1)\n",
    "#             if score>=0.1:\n",
    "#                 cv2.rectangle(img,\n",
    "#                               (box[0], box[1]),\n",
    "#                               (box[2], box[3]),\n",
    "#                               color[i], 10)\n",
    "\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    p['bbox']= all_bbox\n",
    "    p['label']= all_label\n",
    "    p['score']= all_score\n",
    "    pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submit= pd.DataFrame()\n",
    "\n",
    "keep_classes= [1,2,3,4,5]\n",
    "for pred in pred:\n",
    "    name= pred['img_name'].split('/')[-1]\n",
    "    bbox= pred['bbox']\n",
    "    label= pred['label']\n",
    "    score= pred['score']\n",
    "    for i in range(len(bbox)):\n",
    "        if label[i] not in keep_classes: continue\n",
    "        r= []\n",
    "        bbox[i][2]-= bbox[i][0]\n",
    "        bbox[i][3]-= bbox[i][1]\n",
    "        r+= [name]\n",
    "        r+= [label[i]]\n",
    "        r+= bbox[i].astype(np.int).tolist()\n",
    "        r+= [score[i]]\n",
    "        submit= submit.append([r], ignore_index= True)\n",
    "\n",
    "\n",
    "submit.columns= ['image_filename', \n",
    "              'label_id',\n",
    "              'x',\n",
    "              'y',\n",
    "              'w',\n",
    "              'h',\n",
    "              'confidence']\n",
    "submit.to_csv('submission.csv', index= False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
