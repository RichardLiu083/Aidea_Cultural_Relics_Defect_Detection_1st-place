{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Faster_RCNN.Train import Train_Faster_RCNN\n",
    "from Faster_RCNN.Test import Test_Faster_RCNN\n",
    "from Faster_RCNN.Valid import Valid_Faster_RCNN\n",
    "from Faster_RCNN.Toolbox import check_dataset\n",
    "\n",
    "seed= 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_dataset= []\n",
    "\n",
    "with open('./Data/train_1.json', 'r', encoding=\"utf-8\") as f:\n",
    "    label= json.load(f)  \n",
    "for i in tqdm(range(len(label['images']))):\n",
    "    data= {}\n",
    "    data['image_path']= './Data/train_img_1/' + label['images'][i]['file_name']\n",
    "    data['bbox']= []\n",
    "    data['label']= []\n",
    "    id= label['images'][i]['id']\n",
    "    \n",
    "    for j in range(len(label['annotations'])):\n",
    "        if id==label['annotations'][j]['image_id']:\n",
    "            box= label['annotations'][j]['bbox']\n",
    "            box[2]+= box[0]\n",
    "            box[3]+= box[1]\n",
    "            data['bbox'].append(box)\n",
    "            data['label'].append(label['annotations'][j]['category_id'])\n",
    "    all_dataset.append(data)\n",
    "    \n",
    "# with open('./Data/train_2.json', 'r', encoding=\"utf-8\") as f:\n",
    "#     label= json.load(f)  \n",
    "# for i in tqdm(range(len(label['images']))):\n",
    "#     data= {}\n",
    "#     data['image_path']= './Data/train_img_2/' + label['images'][i]['file_name']\n",
    "#     data['bbox']= []\n",
    "#     data['label']= []\n",
    "#     id= label['images'][i]['id']\n",
    "    \n",
    "#     for j in range(len(label['annotations'])):\n",
    "#         if id==label['annotations'][j]['image_id']:\n",
    "#             box= label['annotations'][j]['bbox']\n",
    "#             box[2]+= box[0]\n",
    "#             box[3]+= box[1]\n",
    "#             data['bbox'].append(box)\n",
    "#             data['label'].append(label['annotations'][j]['category_id'])\n",
    "#     all_dataset.append(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_thr= 0.3\n",
    "df= pd.read_csv('Data/submission_0.475_1234+5.csv')\n",
    "df= df[df['confidence']>conf_thr]\n",
    "\n",
    "all_img_name= list(set(df['image_filename']))\n",
    "for name in tqdm(all_img_name):\n",
    "    data= df[df['image_filename']==name]\n",
    "    bbox= data[['x', 'y', 'w', 'h']].values\n",
    "    for i in range(len(bbox)):\n",
    "        bbox[i][2]+= bbox[i][0]\n",
    "        bbox[i][3]+= bbox[i][1]\n",
    "    label= data['label_id']\n",
    "    \n",
    "    data= {}\n",
    "    data['image_path']= f'Data/test_img/{name}'\n",
    "    data['bbox']= np.array(bbox)\n",
    "    data['label']= np.array(label)\n",
    "    all_dataset.append(data)\n",
    "    \n",
    "all_dataset= check_dataset(all_dataset[:])\n",
    "all_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過濾標籤類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_classes= [1,2,3,4,5]\n",
    "\n",
    "drop_sample= []\n",
    "for i, data in enumerate(tqdm(all_dataset)):\n",
    "    \n",
    "    bbox= data['bbox']\n",
    "    label= data['label']\n",
    "    \n",
    "    drop_indx= []\n",
    "    for j in range(len(label)):\n",
    "        if label[j] not in keep_classes:\n",
    "            drop_indx.append(j)\n",
    "            \n",
    "    data['bbox']= np.delete(bbox, drop_indx, axis= 0)\n",
    "    data['label']= np.delete(label, drop_indx, axis= 0)\n",
    "    \n",
    "    if len(data['bbox'])==0: drop_sample.append(i)\n",
    "\n",
    "all_dataset= np.delete(all_dataset, drop_sample, axis= 0)\n",
    "\n",
    "print('drop empty sample: {}'.format(len(drop_sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將具有大量bbox的資料移至validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "drop_indx= []\n",
    "for i, data in enumerate(tqdm(all_dataset)):\n",
    "    \n",
    "    #img= cv2.imread(data['image_path'])\n",
    "    bbox= data['bbox']\n",
    "    bbox= np.array(bbox).astype(np.int)\n",
    "\n",
    "    if len(bbox)>150 and 'test_img' not in data['image_path']:\n",
    "        drop_indx.append(i)\n",
    "        continue\n",
    "        print(len(bbox))\n",
    "        for box in bbox:\n",
    "            cv2.rectangle(img,\n",
    "                          (box[0], box[1]),\n",
    "                          (box[2], box[3]),\n",
    "                          (255, 0, 0), 10)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "vali_dataset= np.array(all_dataset)[drop_indx]\n",
    "train_dataset= np.delete(all_dataset, drop_indx, axis= 0)\n",
    "print('move {} sample to validation'.format(len(drop_indx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset sample\n",
    "#For every data in train_dataset:\n",
    "#    image_path: full path of image\n",
    "#    bbox: [ [left_top_x, left_top_y, right_bottom_x, right_bottom_y], ... ]\n",
    "#    label: [ 1, 2, 3, ... ]  # label numbering start from 1, every label correspond to one box in bbox\n",
    "#\n",
    "#example:\n",
    "#  [\n",
    "#     {'image_path': 'train/img/1615187460.03881810.jpg',\n",
    "#      'bbox': array([[ 1.,  9., 31., 47.],\n",
    "#         [33.,  9., 61., 47.],\n",
    "#         [63.,  9., 93., 47.]], dtype=float32),\n",
    "#      'label': [1, 1, 1]},\n",
    "#  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label start from 1, 0 is background class.\n",
    "\n",
    "all_backbone=[\n",
    "    'resnet18',\n",
    "    'resnet34',\n",
    "    'resnet50',\n",
    "    'resnet101',\n",
    "    'resnet152',\n",
    "    'resnext50_32x4d',\n",
    "    'resnext101_32x8d',\n",
    "    'wide_resnet50_2',\n",
    "    'wide_resnet101_2',\n",
    "]\n",
    "\n",
    "optimizer=[\n",
    "    'adam',\n",
    "    'sgd',\n",
    "    'rmsprop',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "multi_scale= list(range(1280, 1792, 32))\n",
    "best_score= 0\n",
    "epoch= 1\n",
    "for ep in range(epoch):\n",
    "    print()\n",
    "    print('epoch:', ep)\n",
    "\n",
    "    Train_CFG= {\n",
    "        'model_architecture': 'FasterRCNN',\n",
    "        'epochs': 1,\n",
    "        'model_backbone': 'resnet152',\n",
    "        'pretrained': True,\n",
    "        'img_size': 1536, \n",
    "        \n",
    "        'lr': 1e-5,\n",
    "        'optimizer': 'adam',\n",
    "        'batch_size': 1,\n",
    "        'anchor_ratio': 2,\n",
    "        \n",
    "        'save_best_model': False,\n",
    "        'save_model_path_and_name': False,#'train_cv_model/faster_rcnn.pth',\n",
    "        'load_model': False, #'test_cv_model/resnet152_1792_best/faster_rcnn_best.pth', \n",
    "        \n",
    "        'mixup': True,\n",
    "        'mosaic': False,\n",
    "        'data_aug': True,\n",
    "        \n",
    "        'valid_train_dataset': False,\n",
    "        'valid_size': 0,\n",
    "        'device': 'gpu:0', # cpu or gpu:0 if you have\n",
    "    }\n",
    "\n",
    "    \n",
    "    if ep!=0: \n",
    "#         choose_size= np.random.choice(multi_scale, 1)[0]\n",
    "#         print(f'choose size: {choose_size}')\n",
    "#         model.transform= GeneralizedRCNNTransform(min_size= choose_size,\n",
    "#                                       max_size= 4096,\n",
    "#                                       image_mean=[0.485, 0.456, 0.406],\n",
    "#                                       image_std=[0.229, 0.224, 0.225])\n",
    "        Train_CFG['load_model']= model\n",
    "\n",
    "    # start training\n",
    "    model= Train_Faster_RCNN(\n",
    "                dataset= train_dataset[:],\n",
    "                CFG= Train_CFG,\n",
    "            )\n",
    "\n",
    "\n",
    "    Valid_CFG= {\n",
    "        'img_size': None,    # None為使用原始解析度\n",
    "        'confidence': 0.001,\n",
    "        'NMS_threshold': 0.5,\n",
    "        'load_model': model,\n",
    "        'device': 'gpu:0',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        valid_IOU, valid_class_IOU, valid_MAP, valid_class_MAP= Valid_Faster_RCNN(\n",
    "                                                                    dataset= vali_dataset,\n",
    "                                                                    CFG= Valid_CFG,\n",
    "                                                                )\n",
    "        if valid_MAP > best_score:\n",
    "            torch.save(model, 'train_cv_model/faster_rcnn_best.pth')\n",
    "            best_score= valid_MAP\n",
    "            print('model save at score:', best_score)\n",
    "    except:\n",
    "        print('model not converage')\n",
    "        \n",
    "    if ep!=0 and ep%5==0:\n",
    "        torch.save(model, 'train_cv_model/faster_rcnn_{}.pth'.format(ep))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
